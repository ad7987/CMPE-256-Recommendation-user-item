{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ddf068-83ef-467c-887b-64388fc87dce",
      "metadata": {
        "id": "b2ddf068-83ef-467c-887b-64388fc87dce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042b3b10-c2f1-4139-aebb-43c3041cc419",
      "metadata": {
        "id": "042b3b10-c2f1-4139-aebb-43c3041cc419"
      },
      "outputs": [],
      "source": [
        "#K_VAL = 1\n",
        "\n",
        "#INPUT_DIR = Path('Test_Train_Data')\n",
        "\n",
        "TRAIN_PATH = \"data_k1_train.txt\"\n",
        "TEST_PATH = \"data_k1_test.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec10225b-c06c-47b8-8069-970e27d0e47d",
      "metadata": {
        "id": "ec10225b-c06c-47b8-8069-970e27d0e47d"
      },
      "outputs": [],
      "source": [
        "def load_data_and_create_matrices(  train_file: Path,\n",
        "                                    test_file: Path ) -> Tuple[sp.csr_matrix, sp.csr_matrix, Dict[int, int], Dict[int, int]]:\n",
        "\n",
        "    raw_data = []\n",
        "\n",
        "    def parse_file(filepath: Path, dataset_type: str) -> None:\n",
        "        if not filepath.exists():\n",
        "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
        "\n",
        "        with filepath.open(\"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 2:\n",
        "                    continue\n",
        "\n",
        "                u_id = int(parts[0])\n",
        "                items = [int(i) for i in parts[1:]]\n",
        "\n",
        "                for i_id in items:\n",
        "                    raw_data.append(\n",
        "                        {\n",
        "                            \"user\": u_id,\n",
        "                            \"item\": i_id,\n",
        "                            \"type\": dataset_type,  # \"train\" or \"test\"\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "    parse_file(train_file, \"train\")\n",
        "    parse_file(test_file, \"test\")\n",
        "\n",
        "    df = pd.DataFrame(raw_data)\n",
        "    print(f\"Loaded {len(df):,} total interactions.\")\n",
        "\n",
        "    df[\"user_idx\"] = df[\"user\"].astype(\"category\").cat.codes\n",
        "    df[\"item_idx\"] = df[\"item\"].astype(\"category\").cat.codes\n",
        "\n",
        "    # Internal index -> original ID\n",
        "    user_map: Dict[int, int] = dict(zip(df[\"user_idx\"], df[\"user\"]))\n",
        "    item_map: Dict[int, int] = dict(zip(df[\"item_idx\"], df[\"item\"]))\n",
        "\n",
        "    n_users = len(user_map)\n",
        "    n_items = len(item_map)\n",
        "\n",
        "    print(f\"Matrix dimensions: {n_users:,} users x {n_items:,} items\")\n",
        "\n",
        "    def build_csr(dataset_type: str) -> sp.csr_matrix:\n",
        "        subset = df[df[\"type\"] == dataset_type]\n",
        "\n",
        "        rows = subset[\"user_idx\"].values\n",
        "        cols = subset[\"item_idx\"].values\n",
        "        data = np.ones(len(subset), dtype=np.float32)\n",
        "\n",
        "        return sp.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
        "\n",
        "    train_matrix = build_csr(\"train\")\n",
        "    test_matrix = build_csr(\"test\")\n",
        "\n",
        "    print(f\"Train nnz: {train_matrix.nnz:,} | Test nnz: {test_matrix.nnz:,}\")\n",
        "\n",
        "    return train_matrix, test_matrix, user_map, item_map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cae323c-d05b-4903-b24c-51af5199956",
        "outputId": "09ba17b9-1230-44ac-b8dc-006da9c82065"
      },
      "source": [
        "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(Path(TRAIN_PATH), Path(TEST_PATH))"
      ],
      "id": "8cae323c-d05b-4903-b24c-51af5199956",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2,380,730 total interactions.\n",
            "Matrix dimensions: 52,643 users x 91,599 items\n",
            "Train nnz: 1,924,739 | Test nnz: 455,991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94046c93-f501-4a78-bf1c-43c89742f108",
      "metadata": {
        "id": "94046c93-f501-4a78-bf1c-43c89742f108"
      },
      "outputs": [],
      "source": [
        "class ItemKNNRecommender:\n",
        "    \"\"\"\n",
        "    Item-Based Collaborative Filtering.\n",
        "    Logic: \"Users who liked Item A also liked Item B.\"\n",
        "    \"\"\"\n",
        "    def __init__(self, n_neighbors=20):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n_neighbors, n_jobs=-1)\n",
        "        self.train_matrix = None\n",
        "        self.item_vectors = None\n",
        "\n",
        "    def fit(self, train_matrix):\n",
        "        \"\"\"\n",
        "        Trains the KNN model.\n",
        "        We want to calculate distance between ITEMS (rows).\n",
        "        \"\"\"\n",
        "        print(f\"Training Item-KNN (k={self.n_neighbors})...\")\n",
        "        self.train_matrix = train_matrix\n",
        "\n",
        "        self.item_vectors = train_matrix.T\n",
        "\n",
        "        # Fit the model on the Item Vectors\n",
        "        self.model.fit(self.item_vectors)\n",
        "\n",
        "    def predict(self, user_idx, top_k=20):\n",
        "        \"\"\"\n",
        "        Predicts items based on the user's history.\n",
        "        \"\"\"\n",
        "        user_history_indices = self.train_matrix[user_idx].indices\n",
        "\n",
        "        if len(user_history_indices) == 0:\n",
        "            return np.array([])\n",
        "\n",
        "        query_indices = user_history_indices\n",
        "\n",
        "        query_vectors = self.item_vectors[query_indices]\n",
        "        distances, neighbor_indices = self.model.kneighbors(query_vectors)\n",
        "\n",
        "        candidate_scores = {}\n",
        "        for i in range(len(query_indices)):\n",
        "            for j in range(self.n_neighbors):\n",
        "                neighbor_idx = neighbor_indices[i, j]\n",
        "                similarity = 1.0 - distances[i, j]\n",
        "\n",
        "                candidate_scores[neighbor_idx] = candidate_scores.get(neighbor_idx, 0) + similarity\n",
        "\n",
        "        for seen_idx in user_history_indices:\n",
        "            if seen_idx in candidate_scores:\n",
        "                del candidate_scores[seen_idx]\n",
        "\n",
        "        sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        top_indices = [idx for idx, score in sorted_candidates[:top_k]]\n",
        "\n",
        "        return np.array(top_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6753e0e-1251-4f50-bca9-513103888ef8",
      "metadata": {
        "id": "a6753e0e-1251-4f50-bca9-513103888ef8"
      },
      "outputs": [],
      "source": [
        "def dcg_at_k(ranked_items, relevant_items, k=20):\n",
        "    \"\"\"\n",
        "    ranked_items: 1D array/list of item indices (internal item_idx)\n",
        "    relevant_items: set of relevant item indices from test_matrix[user_idx].indices\n",
        "    \"\"\"\n",
        "    dcg = 0.0\n",
        "    for rank, item in enumerate(ranked_items[:k], start=1):\n",
        "        if item in relevant_items:\n",
        "            dcg += 1.0 / np.log2(rank + 1)\n",
        "    return dcg\n",
        "\n",
        "\n",
        "def ndcg_for_user(model, user_idx, test_matrix, k=20):\n",
        "    \"\"\"\n",
        "    Compute NDCG@k for a single user_idx using the fitted ItemKNNRecommender.\n",
        "    \"\"\"\n",
        "    rel_items = test_matrix[user_idx].indices\n",
        "    if len(rel_items) == 0:\n",
        "        return None\n",
        "\n",
        "    rel_set = set(rel_items)\n",
        "\n",
        "    # Predicted top-K items\n",
        "    preds = model.predict(user_idx, top_k=k)\n",
        "    if preds is None or len(preds) == 0:\n",
        "        return None\n",
        "\n",
        "    dcg = dcg_at_k(preds, rel_set, k=k)\n",
        "\n",
        "    ideal_len = min(len(rel_set), k)\n",
        "    if ideal_len == 0:\n",
        "        return None\n",
        "    idcg = sum(1.0 / np.log2(r + 1) for r in range(1, ideal_len + 1))\n",
        "\n",
        "    return dcg / idcg if idcg > 0 else None\n",
        "\n",
        "\n",
        "def evaluate_item_knn_segmented(model,\n",
        "                                train_matrix,\n",
        "                                test_matrix,\n",
        "                                user_map,\n",
        "                                user_segment,\n",
        "                                k=20):\n",
        "    \"\"\"\n",
        "    Compute overall NDCG@k and NDCG@k per user segment:\n",
        "    - regular\n",
        "    - heavy\n",
        "    - extreme\n",
        "\n",
        "    user_map: dict[user_idx -> raw_user_id]\n",
        "    user_segment: dict[raw_user_id -> \"regular\"/\"heavy\"/\"extreme\"]\n",
        "    \"\"\"\n",
        "    n_users = train_matrix.shape[0]\n",
        "\n",
        "    overall_scores = []\n",
        "    seg_scores = {\n",
        "        \"regular\": [],\n",
        "        \"heavy\": [],\n",
        "        \"extreme\": []\n",
        "    }\n",
        "\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for u_idx in tqdm(range(n_users), desc=\"Evaluating Item-KNN\"):\n",
        "        ndcg_u = ndcg_for_user(model, u_idx, test_matrix, k=k)\n",
        "        if ndcg_u is None:\n",
        "            continue\n",
        "\n",
        "        overall_scores.append(ndcg_u)\n",
        "\n",
        "        raw_u = user_map[u_idx]\n",
        "        seg = user_segment.get(raw_u, None)\n",
        "        if seg in seg_scores:\n",
        "            seg_scores[seg].append(ndcg_u)\n",
        "\n",
        "    overall_ndcg = float(np.mean(overall_scores)) if overall_scores else 0.0\n",
        "    seg_ndcg = {\n",
        "        seg: (float(np.mean(vals)) if len(vals) > 0 else None)\n",
        "        for seg, vals in seg_scores.items()\n",
        "    }\n",
        "\n",
        "    print(f\"\\nOverall NDCG@{k}: {overall_ndcg:.4f}\")\n",
        "    for seg in [\"regular\", \"heavy\", \"extreme\"]:\n",
        "        v = seg_ndcg[seg]\n",
        "        if v is None:\n",
        "            print(f\"  {seg:8s}: no users evaluated\")\n",
        "        else:\n",
        "            print(f\"  {seg:8s}: {v:.4f} (n={len(seg_scores[seg])})\")\n",
        "\n",
        "    return overall_ndcg, seg_ndcg, seg_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcca60b3-dd13-4daa-ba75-c801181f6626",
      "metadata": {
        "id": "bcca60b3-dd13-4daa-ba75-c801181f6626"
      },
      "outputs": [],
      "source": [
        "def ndcg_at_k(predicted_items, true_items, k=20):\n",
        "    \"\"\"\n",
        "    predicted_items: iterable of item_idx predicted for the user\n",
        "    true_items: iterable or set of relevant item_idx from test\n",
        "    \"\"\"\n",
        "    if len(true_items) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    true_set = set(true_items)\n",
        "\n",
        "    dcg = 0.0\n",
        "    for rank, item in enumerate(predicted_items[:k], start=1):\n",
        "        if item in true_set:\n",
        "            dcg += 1.0 / np.log2(rank + 1)\n",
        "\n",
        "    ideal_len = min(len(true_set), k)\n",
        "    idcg = sum(1.0 / np.log2(i + 1) for i in range(1, ideal_len + 1))\n",
        "\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1705d4-a701-4feb-a6a0-51f9b5199956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1705d4-a701-4feb-a6a0-51f9b5199956",
        "outputId": "33e83918-4347-4afb-8f89-bb24148c8f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation built:\n",
            "regular 43985\n",
            "heavy 7904\n",
            "extreme 754\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "user_train_counts = defaultdict(int)\n",
        "train_users, train_items = train_matrix.nonzero()\n",
        "for u in train_users:\n",
        "    user_train_counts[u] += 1\n",
        "\n",
        "def get_user_segment(count):\n",
        "    if 11 <= count <= 50:\n",
        "        return \"regular\"\n",
        "    elif 51 <= count <= 200:\n",
        "        return \"heavy\"\n",
        "    elif count > 200:\n",
        "        return \"extreme\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "user_segment = {}\n",
        "\n",
        "for user_idx, raw_id in user_map.items():\n",
        "    seg = get_user_segment(user_train_counts[user_idx])\n",
        "    if seg is not None:\n",
        "        user_segment[raw_id] = seg\n",
        "\n",
        "print(\"Segmentation built:\")\n",
        "for s in [\"regular\", \"heavy\", \"extreme\"]:\n",
        "    print(s, sum(1 for x in user_segment.values() if x == s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f860b9a-2231-4cc9-80de-17fc2da95730",
      "metadata": {
        "id": "9f860b9a-2231-4cc9-80de-17fc2da95730"
      },
      "outputs": [],
      "source": [
        "def knn_pipeline(\n",
        "    train_matrix,\n",
        "    test_matrix,\n",
        "    user_map,\n",
        "    item_map,\n",
        "    top_k=20,\n",
        "    n_neighbors=20,\n",
        "    user_segment=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Orchestrates the training and evaluation of the Item-KNN model.\n",
        "    Returns: output_df, avg_ndcg_score\n",
        "\n",
        "    If user_segment is provided (raw_user_id -> 'regular'/'heavy'/'extreme'),\n",
        "    also prints NDCG@k per segment.\n",
        "    \"\"\"\n",
        "\n",
        "    model = ItemKNNRecommender(n_neighbors=n_neighbors)\n",
        "    model.fit(train_matrix)\n",
        "\n",
        "    ndcg_scores = []\n",
        "    output_rows = []\n",
        "\n",
        "    seg_scores = None\n",
        "    if user_segment is not None:\n",
        "        from collections import defaultdict\n",
        "        seg_scores = defaultdict(list)\n",
        "\n",
        "    test_users = np.unique(test_matrix.nonzero()[0])\n",
        "    n_test_users = len(test_users)\n",
        "\n",
        "    print(f\"Evaluating {n_test_users:,} users\")\n",
        "\n",
        "    for i, user_idx in tqdm(enumerate(test_users, 1), total=n_test_users, desc=\"Predicting\"):\n",
        "        top_indices = model.predict(user_idx, top_k=top_k)\n",
        "\n",
        "        true_items = test_matrix[user_idx].indices\n",
        "        if len(true_items) == 0:\n",
        "            continue\n",
        "\n",
        "        score = ndcg_at_k(top_indices, true_items, k=top_k)\n",
        "        ndcg_scores.append(score)\n",
        "\n",
        "        real_user_id = user_map.get(user_idx, f\"User_{user_idx}\")\n",
        "        real_item_ids = [item_map.get(idx, f\"Item_{idx}\") for idx in top_indices]\n",
        "\n",
        "        output_rows.append({\n",
        "            'user_id': real_user_id,\n",
        "            'recommended_items': real_item_ids\n",
        "        })\n",
        "\n",
        "        if seg_scores is not None:\n",
        "            seg = user_segment.get(real_user_id, None)\n",
        "            if seg is not None:\n",
        "                seg_scores[seg].append(score)\n",
        "\n",
        "        if i % 5000 == 0:\n",
        "            current_avg = np.mean(ndcg_scores)\n",
        "            tqdm.write(f\"Processed {i} users. Current Avg NDCG@{top_k}: {current_avg:.4f}\")\n",
        "\n",
        "    avg_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
        "\n",
        "    print(\"\\nRESULTS:\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Evaluated Users: {len(ndcg_scores):,}\")\n",
        "    print(f\"Average NDCG@{top_k}: {avg_ndcg:.4f}\")\n",
        "\n",
        "    if seg_scores is not None:\n",
        "        print(\"\\nSegment-wise NDCG:\")\n",
        "        for seg in [\"regular\", \"heavy\", \"extreme\"]:\n",
        "            vals = seg_scores.get(seg, [])\n",
        "            if len(vals) == 0:\n",
        "                print(f\"  {seg:8s}: no users\")\n",
        "            else:\n",
        "                print(f\"  {seg:8s}: {np.mean(vals):.4f} (n={len(vals)})\")\n",
        "\n",
        "    return pd.DataFrame(output_rows), avg_ndcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf08c45-963a-4dd2-b8ba-9e0d5c9629df",
      "metadata": {
        "id": "cbf08c45-963a-4dd2-b8ba-9e0d5c9629df"
      },
      "outputs": [],
      "source": [
        "def save_recommendations(df: pd.DataFrame, filename_base: str = \"recommendations\", output_dir: str = \".\"):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    txt_path = os.path.join(output_dir, f\"{filename_base}.txt\")\n",
        "\n",
        "    with open(txt_path, 'w') as f:\n",
        "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Writing TXT\"):\n",
        "            user_id = row['user_id']\n",
        "            items_str = \" \".join(map(str, row['recommended_items']))\n",
        "            f.write(f\"{user_id} {items_str}\\n\")\n",
        "\n",
        "    print(f\"Saved results as TXT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "872e27f4-37ca-4a4c-8a48-7cf02d78ef77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "872e27f4-37ca-4a4c-8a48-7cf02d78ef77",
        "outputId": "8d5db68f-8d49-4afd-a9ce-a274fb9f0b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Item-KNN (k=10)...\n",
            "Evaluating 52,643 users\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  10%|▉         | 5004/52643 [04:50<38:18, 20.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5000 users. Current Avg NDCG@20: 0.0811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  19%|█▉        | 10004/52643 [09:10<37:08, 19.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10000 users. Current Avg NDCG@20: 0.0795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  28%|██▊       | 15003/52643 [13:20<31:10, 20.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15000 users. Current Avg NDCG@20: 0.0805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  38%|███▊      | 20004/52643 [17:33<23:19, 23.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20000 users. Current Avg NDCG@20: 0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  47%|████▋     | 25001/52643 [21:32<26:03, 17.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25000 users. Current Avg NDCG@20: 0.0916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  57%|█████▋    | 30003/52643 [25:36<16:14, 23.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30000 users. Current Avg NDCG@20: 0.0986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  66%|██████▋   | 35001/52643 [29:28<14:37, 20.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 35000 users. Current Avg NDCG@20: 0.1062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  76%|███████▌  | 40002/52643 [33:19<09:22, 22.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 40000 users. Current Avg NDCG@20: 0.1137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  85%|████████▌ | 45003/52643 [37:07<05:51, 21.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 45000 users. Current Avg NDCG@20: 0.1199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting:  95%|█████████▍| 50003/52643 [40:53<01:56, 22.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 50000 users. Current Avg NDCG@20: 0.1259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 52643/52643 [42:47<00:00, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RESULTS:\n",
            "========================================\n",
            "Evaluated Users: 52,643\n",
            "Average NDCG@20: 0.1283\n",
            "\n",
            "Segment-wise NDCG:\n",
            "  regular : 0.1255 (n=43985)\n",
            "  heavy   : 0.1378 (n=7904)\n",
            "  extreme : 0.1921 (n=754)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output_df, avg_ndcg = knn_pipeline(\n",
        "    train_matrix=train_matrix,\n",
        "    test_matrix=test_matrix,\n",
        "    user_map=user_map,\n",
        "    item_map=item_map,\n",
        "    top_k=20,\n",
        "    n_neighbors=10,\n",
        "    user_segment=user_segment\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5337abf5-c6c6-4788-8b3a-e2c1d1a8ada6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5337abf5-c6c6-4788-8b3a-e2c1d1a8ada6",
        "outputId": "1d1c0ef7-91a4-4fba-a52d-e6add78acea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing TXT: 100%|██████████| 52643/52643 [00:01<00:00, 30348.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results as TXT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "save_recommendations(output_df, filename_base=\"results\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
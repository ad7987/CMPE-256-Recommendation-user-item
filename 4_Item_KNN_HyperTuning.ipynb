{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN5uCdOIA2Dj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#K_VAL = 1\n",
        "\n",
        "#INPUT_DIR = Path('Test_Train_Data')\n",
        "\n",
        "TRAIN_PATH = \"data_k1_train.txt\"\n",
        "TEST_PATH = \"data_k1_test.txt\""
      ],
      "metadata": {
        "id": "TTkOQiJ2A66l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_and_create_matrices(  train_file: Path,\n",
        "                                    test_file: Path ) -> Tuple[sp.csr_matrix, sp.csr_matrix, Dict[int, int], Dict[int, int]]:\n",
        "\n",
        "    raw_data = []\n",
        "\n",
        "    def parse_file(filepath: Path, dataset_type: str) -> None:\n",
        "        if not filepath.exists():\n",
        "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
        "\n",
        "        with filepath.open(\"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 2:\n",
        "                    continue\n",
        "\n",
        "                u_id = int(parts[0])\n",
        "                items = [int(i) for i in parts[1:]]\n",
        "\n",
        "                for i_id in items:\n",
        "                    raw_data.append(\n",
        "                        {\n",
        "                            \"user\": u_id,\n",
        "                            \"item\": i_id,\n",
        "                            \"type\": dataset_type,\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "    parse_file(train_file, \"train\")\n",
        "    parse_file(test_file, \"test\")\n",
        "\n",
        "    df = pd.DataFrame(raw_data)\n",
        "    print(f\"Loaded {len(df):,} total interactions.\")\n",
        "\n",
        "    df[\"user_idx\"] = df[\"user\"].astype(\"category\").cat.codes\n",
        "    df[\"item_idx\"] = df[\"item\"].astype(\"category\").cat.codes\n",
        "\n",
        "\n",
        "    user_map: Dict[int, int] = dict(zip(df[\"user_idx\"], df[\"user\"]))\n",
        "    item_map: Dict[int, int] = dict(zip(df[\"item_idx\"], df[\"item\"]))\n",
        "\n",
        "    n_users = len(user_map)\n",
        "    n_items = len(item_map)\n",
        "\n",
        "    print(f\"Matrix dimensions: {n_users:,} users x {n_items:,} items\")\n",
        "\n",
        "    def build_csr(dataset_type: str) -> sp.csr_matrix:\n",
        "        subset = df[df[\"type\"] == dataset_type]\n",
        "\n",
        "        rows = subset[\"user_idx\"].values\n",
        "        cols = subset[\"item_idx\"].values\n",
        "        data = np.ones(len(subset), dtype=np.float32)\n",
        "\n",
        "        return sp.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
        "\n",
        "    train_matrix = build_csr(\"train\")\n",
        "    test_matrix = build_csr(\"test\")\n",
        "\n",
        "    print(f\"Train nnz: {train_matrix.nnz:,} | Test nnz: {test_matrix.nnz:,}\")\n",
        "\n",
        "    return train_matrix, test_matrix, user_map, item_map"
      ],
      "metadata": {
        "id": "4x9h61fuA69Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_matrix, test_matrix, user_map, item_map = load_data_and_create_matrices(Path(TRAIN_PATH), Path(TEST_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRrnTp9zA6_2",
        "outputId": "778ea717-f1b2-4d18-a214-8e8bc8df4879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2,380,730 total interactions.\n",
            "Matrix dimensions: 52,643 users x 91,599 items\n",
            "Train nnz: 1,924,739 | Test nnz: 455,991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_users, n_items = train_matrix.shape"
      ],
      "metadata": {
        "id": "_wthdE9GGti7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# item_degree[i] = # of interactions for item i\n",
        "item_degree = np.asarray(train_matrix.sum(axis=0)).ravel()\n",
        "print(\"Item degrees shape:\", item_degree.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc6sBALnBNHC",
        "outputId": "87a693ee-1ddb-46f0-96e0-7fb82da62c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item degrees shape: (91599,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "cooccur = defaultdict(int)\n",
        "\n",
        "print(\"Building item-item co-occurrence map...\")\n",
        "for u in tqdm(range(n_users), desc=\"Users\"):\n",
        "    items = train_matrix[u].indices\n",
        "    if len(items) < 2:\n",
        "        continue\n",
        "\n",
        "    items = np.sort(items)\n",
        "    for i in range(len(items)):\n",
        "        for j in range(i + 1, len(items)):\n",
        "            a, b = items[i], items[j]\n",
        "            cooccur[(a, b)] += 1\n",
        "\n",
        "print(\"Number of item pairs with nonzero co-occurrence:\", len(cooccur))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbw51JpXBND5",
        "outputId": "6ee29839-f034-4ce3-9e54-2d6373c5458a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building item-item co-occurrence map...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Users: 100%|██████████| 52643/52643 [02:10<00:00, 404.71it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of item pairs with nonzero co-occurrence: 113008636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_NEIGHBORS = 5  # you can tune this\n",
        "\n",
        "neighbors_tmp = [[] for _ in range(n_items)]\n",
        "\n",
        "print(\"Computing Jaccard similarities from co-occurrence...\")\n",
        "for (a, b), inter in tqdm(cooccur.items(), desc=\"Pairs\"):\n",
        "    da = item_degree[a]\n",
        "    db = item_degree[b]\n",
        "    union = da + db - inter\n",
        "    if union <= 0:\n",
        "        continue\n",
        "    sim = inter / union\n",
        "    if sim <= 0:\n",
        "        continue\n",
        "\n",
        "    neighbors_tmp[a].append((b, sim))\n",
        "    neighbors_tmp[b].append((a, sim))\n",
        "\n",
        "neighbors_idx = np.full((n_items, K_NEIGHBORS), -1, dtype=np.int32)\n",
        "neighbors_sim = np.zeros((n_items, K_NEIGHBORS), dtype=np.float32)\n",
        "\n",
        "for i in range(n_items):\n",
        "    sims = neighbors_tmp[i]\n",
        "    if not sims:\n",
        "        continue\n",
        "    sims.sort(key=lambda x: x[1], reverse=True)\n",
        "    sims = sims[:K_NEIGHBORS]\n",
        "\n",
        "    for k, (j, s) in enumerate(sims):\n",
        "        neighbors_idx[i, k] = j\n",
        "        neighbors_sim[i, k] = s\n",
        "\n",
        "print(\"neighbors_idx shape:\", neighbors_idx.shape)\n",
        "print(\"neighbors_sim shape:\", neighbors_sim.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRc9HyakFp5B",
        "outputId": "53d03971-38e5-48ac-b9fc-27ca520182b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing Jaccard similarities from co-occurrence...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pairs: 100%|██████████| 113008636/113008636 [02:16<00:00, 826527.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neighbors_idx shape: (91599, 5)\n",
            "neighbors_sim shape: (91599, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at_k(r, k):\n",
        "    r = np.asarray(r, dtype=float)[:k]\n",
        "    if r.size == 0:\n",
        "        return 0.0\n",
        "    discounts = np.log2(np.arange(2, r.size + 2))\n",
        "    dcg = np.sum(r / discounts)\n",
        "    ideal = np.sort(r)[::-1]\n",
        "    idcg = np.sum(ideal / discounts)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n"
      ],
      "metadata": {
        "id": "fyohuJ-JF0XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_user_jaccard(\n",
        "    u_idx,\n",
        "    train_matrix,\n",
        "    neighbors_idx,\n",
        "    neighbors_sim,\n",
        "    topn=20\n",
        "):\n",
        "    user_row = train_matrix[u_idx].toarray().ravel()\n",
        "    seen = user_row.nonzero()[0]\n",
        "\n",
        "    if len(seen) == 0:\n",
        "        return np.array([], dtype=int), np.array([])\n",
        "\n",
        "    scores = np.zeros(train_matrix.shape[1], dtype=np.float32)\n",
        "\n",
        "    for it in seen:\n",
        "        nbrs = neighbors_idx[it]\n",
        "        sims = neighbors_sim[it]\n",
        "\n",
        "        mask = nbrs >= 0\n",
        "        nbrs = nbrs[mask]\n",
        "        sims = sims[mask]\n",
        "\n",
        "        scores[nbrs] += sims\n",
        "\n",
        "    scores[seen] = -np.inf\n",
        "\n",
        "    valid = np.where(np.isfinite(scores))[0]\n",
        "    if len(valid) == 0:\n",
        "        return np.array([], dtype=int), np.array([])\n",
        "\n",
        "    top_idx = np.argpartition(scores[valid], -topn)[-topn:]\n",
        "    top_items = valid[top_idx]\n",
        "    top_items = top_items[np.argsort(scores[top_items])[::-1]]\n",
        "\n",
        "    return top_items, scores[top_items]\n"
      ],
      "metadata": {
        "id": "0azTDDmWF0Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_items_per_user = [test_matrix[u].indices for u in range(n_users)]\n",
        "print(\"Prepared test items per user.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20y-jLEIF0cz",
        "outputId": "9a473640-9397-40fc-aca5-cf030538b77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared test items per user.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOPK = 20\n",
        "\n",
        "EVAL_USER_LIMIT = None\n",
        "\n",
        "all_user_indices = np.arange(n_users)\n",
        "if EVAL_USER_LIMIT is not None:\n",
        "    all_user_indices = all_user_indices[:EVAL_USER_LIMIT]\n",
        "\n",
        "print(f\"Evaluating {len(all_user_indices)} users...\")\n",
        "\n",
        "ndcg_list = []\n",
        "predictions_for_save = []\n",
        "\n",
        "processed = 0\n",
        "\n",
        "for u_idx in tqdm(all_user_indices, desc=\"Predicting (Jaccard KNN)\"):\n",
        "    true_items = test_items_per_user[u_idx]\n",
        "    if len(true_items) == 0:\n",
        "        continue\n",
        "\n",
        "    rec_items, _ = recommend_user_jaccard(\n",
        "        u_idx=u_idx,\n",
        "        train_matrix=train_matrix,\n",
        "        neighbors_idx=neighbors_idx,\n",
        "        neighbors_sim=neighbors_sim,\n",
        "        topn=TOPK\n",
        "    )\n",
        "\n",
        "    orig_user = user_map[u_idx]\n",
        "    orig_items = [item_map[i] for i in rec_items]\n",
        "    line = \" \".join([str(orig_user)] + [str(i) for i in orig_items])\n",
        "    predictions_for_save.append(line)\n",
        "\n",
        "    # ndcg\n",
        "    relevance = [1 if i in true_items else 0 for i in rec_items]\n",
        "    ndcg_val = ndcg_at_k(relevance, TOPK)\n",
        "    ndcg_list.append(ndcg_val)\n",
        "\n",
        "    processed += 1\n",
        "    if processed % 5000 == 0:\n",
        "        print(f\"Processed {processed} users. Current Avg NDCG@{TOPK}: {np.mean(ndcg_list):.4f}\")\n",
        "\n",
        "avg_ndcg = np.mean(ndcg_list) if ndcg_list else 0.0\n",
        "print(\"\\nFINAL RESULT (Global Jaccard Item-KNN):\")\n",
        "print(f\"NDCG@{TOPK}: {avg_ndcg:.4f}\")\n",
        "\n",
        "filename = f\"jaccard_knn_k{K_NEIGHBORS}_top{TOPK}.txt\"\n",
        "with open(filename, \"w\") as f:\n",
        "    for row in predictions_for_save:\n",
        "        f.write(row + \"\\n\")\n",
        "\n",
        "print(\"Saved predictions to:\", filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-A6qMIhF0gN",
        "outputId": "ab49bdad-e392-4977-a861-121f2b6a530c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 52643 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  10%|▉         | 5025/52643 [00:22<03:34, 221.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5000 users. Current Avg NDCG@20: 0.2417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  19%|█▉        | 10022/52643 [00:44<03:06, 227.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10000 users. Current Avg NDCG@20: 0.2328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  29%|██▊       | 15043/52643 [01:06<02:50, 220.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15000 users. Current Avg NDCG@20: 0.2313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  38%|███▊      | 20037/52643 [01:28<02:24, 226.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20000 users. Current Avg NDCG@20: 0.2396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  48%|████▊     | 25035/52643 [01:49<02:03, 222.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25000 users. Current Avg NDCG@20: 0.2487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  57%|█████▋    | 30039/52643 [02:11<01:39, 227.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30000 users. Current Avg NDCG@20: 0.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  67%|██████▋   | 35034/52643 [02:33<01:15, 234.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 35000 users. Current Avg NDCG@20: 0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  76%|███████▌  | 40030/52643 [02:54<00:54, 230.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 40000 users. Current Avg NDCG@20: 0.2811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  86%|████████▌ | 45023/52643 [03:16<00:33, 227.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 45000 users. Current Avg NDCG@20: 0.2893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN):  95%|█████████▌| 50040/52643 [03:38<00:11, 228.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 50000 users. Current Avg NDCG@20: 0.2975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting (Jaccard KNN): 100%|██████████| 52643/52643 [03:49<00:00, 229.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL RESULT (Global Jaccard Item-KNN):\n",
            "NDCG@20: 0.2999\n",
            "Saved predictions to: jaccard_knn_k5_top20.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-AHtMl_jG0G7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}